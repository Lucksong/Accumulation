# 11.flink流处理对流量进行统计的转换操作

---

**1 环境**

- 从kafka读取到关于流量的原始数据流DataStream<SFlowRecord> baseFlow，SFlowRecord包括ip地址、出入端口、流量大小TrafficBytes和流量包数TrafficPackets
- 对数据流进行转换操作，最后存储入elasticsearch

**2 流转换思路**

- 对baseFlow根据ip、出端口和ip、入端口进行分流分别统计ip的出、入流量；在出流量流统计出流量时，相同ip的入流量设0，出流量相加；在入流量流统计入流量时，相同ip的出流量设0，入流量相加；最后将出入流量流对应的出入流量分别相加合为一条数据流写入es
- 流转换时使用滚动窗口(指定时间为2m)
- SimpleSFlowRecord继承SFlowRecord，添加了出入端口inPort、outPort属性，分流统计时分别将出入端口设置为流的端口port，合流时按照ip、port进行分组

**3 代码**

- 分流统计入流量

~~~
            // 分组条件为相同ip(agentId)和入端口(inPort)
            String[] inportKeyByFields = {"agentId", "inPort"};
            // 入流量，SimpleSFlowRecord为定义了出入流量的Flowrecord继承类
            DataStream<SimpleSFlowRecord> inStream = baseFlow.map(record->{
                //端口设为入端口，出端口TrafficBytes，TrafficPackets设0，入端口流量设为记录的流量
                record.setVxLanPayload(null);
                SimpleSFlowRecord simpleSFlowRecord = new SimpleSFlowRecord();
                simpleSFlowRecord.setAgentId(record.getAgentId());
                simpleSFlowRecord.setTimestamp(record.getTimestamp());
                simpleSFlowRecord.setPort(record.getInPort());
                simpleSFlowRecord.setInPort(record.getInPort());
                simpleSFlowRecord.setOutPort(record.getOutPort());
                simpleSFlowRecord.setInTrafficBytes(record.getTrafficBytes());
                simpleSFlowRecord.setInTrafficPackets(record.getTrafficPackets());
                simpleSFlowRecord.setOutTrafficBytes(0);
                simpleSFlowRecord.setOutTrafficPackets(0);
                return simpleSFlowRecord;
            }).keyBy(
                    inportKeyByFields
            ).window(
                    TumblingEventTimeWindows.of(Time.minutes(2))
            ).reduce(new ReduceFunction<SimpleSFlowRecord>() {
                @Override
                public SimpleSFlowRecord reduce(SimpleSFlowRecord value1, SimpleSFlowRecord value2) throws Exception {
                    value1.setTimestamp(Math.max(value1.getTimestamp(), value2.getTimestamp()));
                    value1.setInTrafficPackets(value1.getInTrafficPackets() + value2.getInTrafficPackets());
                    value1.setInTrafficBytes(value1.getInTrafficBytes() + value2.getInTrafficBytes());
                    return value1;
                }
            });
~~~

- 分流统计出流量
~~~
            // 分组条件为相同ip(agentId)和出端口(outPort)
            String[] outportKeyByFields = {"agentId", "outPort"};
            DataStream<SimpleSFlowRecord> outStream = baseFlow.map(record->{
                //端口设为出端口，入端口TrafficBytes，TrafficPackets设0，出端口流量设为记录的流量
                record.setVxLanPayload(null);
                SimpleSFlowRecord simpleSFlowRecord = new SimpleSFlowRecord();
                simpleSFlowRecord.setAgentId(record.getAgentId());
                simpleSFlowRecord.setTimestamp(record.getTimestamp());
                simpleSFlowRecord.setPort(record.getOutPort());
                simpleSFlowRecord.setInPort(record.getInPort());
                simpleSFlowRecord.setOutPort(record.getOutPort());
                simpleSFlowRecord.setInTrafficBytes(0);
                simpleSFlowRecord.setInTrafficPackets(0);
                simpleSFlowRecord.setOutTrafficBytes(record.getTrafficBytes());
                simpleSFlowRecord.setOutTrafficPackets(record.getTrafficPackets());
                return simpleSFlowRecord;
            }).keyBy(
                    outportKeyByFields
            ).window(
                    TumblingEventTimeWindows.of(Time.minutes(2))
            ).reduce(new ReduceFunction<SimpleSFlowRecord>() {
                @Override
                public SimpleSFlowRecord reduce(SimpleSFlowRecord value1, SimpleSFlowRecord value2) throws Exception {
                    value1.setTimestamp(Math.max(value1.getTimestamp(), value2.getTimestamp()));
                    value1.setOutTrafficPackets(value1.getOutTrafficPackets() + value2.getOutTrafficPackets());
                    value1.setOutTrafficBytes(value1.getOutTrafficBytes() + value2.getOutTrafficBytes());
                    return value1;
                }
            });
~~~

- 出入流量流相加合流写入es
~~~
            // 分组条件为相同ip(agentId)和端口(port)
            String[] keyByFields = {"agentId", "port"};
            // 把相同端口出入流量统计到一条记录上
            inStream.union(
                    outStream
            ).keyBy(
                    keyByFields
            ).window(
                    TumblingEventTimeWindows.of(Time.minutes(2))
            ).apply(new WindowFunction<SimpleSFlowRecord, SimpleSFlowRecord, Tuple, TimeWindow>() {
                @Override
                public void apply(Tuple tuple, TimeWindow timeWindow, Iterable<SimpleSFlowRecord> iterable, Collector<SimpleSFlowRecord> collector) throws Exception {
                    SimpleSFlowRecord temp = new SimpleSFlowRecord();
                    temp.setTimestamp(timeWindow.getEnd()/1000);
                    long outTB = 0, outTP = 0;
                    long inTB = 0, inTP = 0;
                    int portValue = 0;
                    String agentIdValue = "";
                    for(SimpleSFlowRecord simpleSFlowRecord : iterable){
                        agentIdValue = simpleSFlowRecord.getAgentId();
                        portValue = simpleSFlowRecord.getPort();
                        inTB += simpleSFlowRecord.getInTrafficBytes();
                        inTP += simpleSFlowRecord.getInTrafficPackets();
                        outTB += simpleSFlowRecord.getOutTrafficBytes();
                        outTP += simpleSFlowRecord.getOutTrafficPackets();
                    }
                    temp.setInTrafficPackets(inTP);
                    temp.setInTrafficBytes(inTB);
                    temp.setAgentId(agentIdValue);
                    temp.setPort(portValue);
                    temp.setOutTrafficBytes(outTB);
                    temp.setOutTrafficPackets(outTP);
                    collector.collect(temp);
                }
            }).addSink(
                    new FlowElasticSearchSink(tableName, schema, Arrays.asList("protocol", "srcIp", "dstIp",
                            "srcPort", "dstPort", "direction", "tcpFlag", "srcOrg", "dstOrg", "trafficBytes", "trafficBytes",
                            "sourceAsNumber", "destinationAsNumber", "ipVersion", "vLinks", "inPort", "outPort"))
            );
~~~
