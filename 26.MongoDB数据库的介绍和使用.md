# MongoDB数据库的介绍和使用

**1 使用java连接MongoDB数据库获取数据**

--1.1 需求

- 系统需要定时访问MOngoDB数据库，获取设备数据生成指定的XML格式文件

--1.2 解决方案

- 使用@Scheduled注解结合cron表达式实现定时

- 与MongoDB数据库建立连接，针对存储不同设备数据的不同Collection，遍历存储数据，如果后期存在单Collection数据量过大超出堆内存问题，可以将相同设备数据按照创建日期分表存放

--1.3 代码

- 定时功能的实现

~~~
@Scheduled(cron="0 0 0 * * ?", zone = "Asia/Shanghai")
public void FullResources(){
    GenerateFullRes generateFullRes = new GenerateFullRes();
    generateFullRes.generateAllXmlFile();
}
~~~

- 连接MongoDB数据库

~~~
public MongoDatabase getConn(){
    try{
        ServerAddress serverAddress = new ServerAddress("192.168.102.130", 27017);
        List<ServerAddress> serverAddressList = new ArrayList<ServerAddress>();
        serverAddressList.add(serverAddress);

        MongoCredential mongoCredential = MongoCredential.createScramSha1Credential(getUserName(), getDataBase(), getPasswd().toCharArray());
        List<MongoCredential> mongoCredentialList = new ArrayList<MongoCredential>();
        mongoCredentialList.add(mongoCredential);

        MongoClient mongoClient = new MongoClient(serverAddressList, mongoCredentialList);

        MongoDatabase mongoDatabase = mongoClient.getDatabase(getDataBase());
        if(mongoDatabase == null){
            System.out.println("MongoDB conn fail.");
        }
        else{
            System.out.println("MongoDB conn succ.");
        }
        return mongoDatabase;

    }catch(Exception e){
        System.err.println(e.getClass().getName() + ": " + e.getMessage());
    }
    return null;

}
~~~

- 带有时间过滤的数据访问存储

~~~
private static Bson timeCondition(LocalDateTime startTime, LocalDateTime endTime){
    Bson condition = Filters.and(Filters.gte("op_time", startTime), Filters.lt("op_time", endTime));
    return condition;
}


public List<Map<String, Object>> findList(MongoCollection<Document> collection, LocalDateTime start, LocalDateTime end){
    /**
        * 1. 获取迭代器FindIterable<Document>,进行过滤
        * 2. 获取游标MongoCursor<Document>
        * 3. 通过游标检索文档集合取用相关信息
        * */
    List<Map<String, Object>> result = new ArrayList<Map<String, Object>>();
    Bson condtionBefore = timeCondition(start, end);
    // Document fetchFiledsAfter = fetchFields();
    //FindIterable<Document> findIterable = collection.find(condtionBefore).projection(fetchFiledsAfter);
    FindIterable<Document> findIterable = collection.find(condtionBefore);
    MongoCursor<Document> mongoCursor = findIterable.iterator();
    while(mongoCursor.hasNext()){
        Document document = mongoCursor.next();
        Document content = document.get("content", new Document());
        Document curdata = content.get("cur_data", new Document());
        System.out.println("curdata: " + curdata);
        Map<String, Object> map = new HashMap<String, Object>();
        map.putAll(curdata);
        result.add(map);
    }
    return result;
}
~~~

**2 MongoDB介绍**

--2.1 基本概念

- 面向集合Collection和文档Document的非关系型数据库，以JSON/BSON格式的文档保存数据

~~~
#BSON是一种类json的一种二进制形式的存储格式，简称Binary JSON，它和JSON一样，支持内嵌的文档对象和数组对象，但是BSON有JSON没有的一些数据类型，  
如Date和BinData类型  
#集合Collection位于单独的一个数据库MongoDB 文档Document集合，它类似关系型数据库（RDBMS）中的表Table。一个集合Collection内的多个文档  
Document可以有多个不同的字段。通常情况下，集合Collection中的文档Document有着相同含义  
#文档Document由key-value构成。文档Document是动态模式,这说明同一集合里的文档不需要有相同的字段和结构。类似于关系型数据库中table中的每一条记录  
#注意与关系型数据库进行术语类比
~~~

- SQL与NOSQL的比较，选用MongoDB的优缺点及场景，该部分主要参考[NoSQL 还是 SQL ？这一篇讲清楚](https://juejin.im/post/5b6d62ddf265da0f491bd200#heading-0)

~~~
2.1.1.SQL缺点：
#存储的是行记录，无法存储数据结构
#表结构schema扩展不方便，如要需要修改表结构，需要执行执行DDL(data definition language)，语句修改，修改期间会导致锁表，部分服务不可用
#全文搜索功能较弱，关系型数据库下只能够进行子字符串的匹配查询，当表的数据逐渐变大的时候，like查询的匹配会非常慢
#存储和处理复杂关系型数据功能较弱，表格数据模型和严格的模式使它们很难添加新的或不同种类的关联信息。

2.1.2.MongoDB使用优点：
#新增字段简单，无需像关系型数据库一样先执行DDL语句修改表结构，程序代码直接读写即可
#容易兼容历史数据，对于历史数据，即使没有新增的字段，也不会导致错误，只会返回空值，此时代码兼容处理即可
#容易存储复杂数据，JSON/BSON是一种强大的描述语言，能够描述复杂的数据结构

2.1.3.MongoDB使用缺点：
#Atomicity(原子性)，仅支持单行/文档级原子性，不支持多行、多文档、多语句原子性
#Isolation(隔离性)，隔离级别仅支持已提交读（Read committed）级别，可能导致不可重复读，幻读的问题
#不支持复杂查询，例如join查询，如果需要join查询，需要多次操作数据库

2.1.4.MongoDB使用场景：
#数据量很大或者未来会变得很大
#表结构不明确，且字段在不断增加
~~~

--2.2 高性能

- 支持Document中嵌入Document减少了数据库系统上的I/O操作以及具有完整的索引支持，支持快速查询

--2.3 高可用，该部分主要参考[MongoDB系列-解决面试中可能遇到的MongoDB复制集（replica set）问题](https://juejin.im/post/5d492ab9f265da03ad1437ed#heading-7)

- 数据复制集，MongoDB 数据库支持服务器之间的数据复制来提供自动故障转移

- MongoDB 使用了其复制(Replica Set)方案，实现自动容错机制为高可用提供了基础。目前，MongoDB 支持两种复制模式：Master / Slave ，主从复制，角色包括 Master 和 Slave ；Replica Set ，复制集复制，角色包括 Primary 和 Secondary 以及 Arbiter (生产环境必选）。

- master/primary：主节点，副本集只能有一个主节点能够确认写入操作来接收所有写操作，并记录其操作日志中的数据集的所有更改(记录在oplog中)。在集群中，当主节点（master）失效，Secondary节点会变为master

- Slave/Secondary：从节点，复制主节点的oplog并将oplog记录的操作应用于其数据集，如果主节点宕机了，将从符合条件的从节点选举选出新的主节点

- Arbiter：仲裁节点，仲裁节点不维护数据集。 仲裁节点的目的是通过响应其他副本集节点的心跳和选举请求来维护副本集中的仲裁

- 复制集架构

~~~
#副本集包含多个数据节点和可选的一个仲裁节点。 而在数据节点中：只有一个主节点(primary node)，其他节点为为从节点(secondary nodes)  
#各个节点成员通过心跳机制进行通信，当主节点与从节点的通信的时间超过配置的electionTimeoutMillis期间（默认为10秒）时，符合条件的从节点要求选举将自己指定  
为新主节点，群集尝试完成新主节点的选举并恢复正常操作  
#标准复制集架构由三台服务器，其中包括三个数据节点(一个主节点、两个从节点)或两个数据节点(一个主节点、一个从节点)和一个仲裁节点两种情况  
#部署奇数个成员，副本集应该确保具有奇数个投票成员，如果您拥有偶数个投票成员，请部署仲裁节点，以便该集合具有奇数个投票成员  

~~~

- 复制集节点类型

~~~
#优先级0型(Priority 0)节点：优先级0型节点不可以成为主节点，不能选举，主要用于备份  
#隐藏型(Hidden)节点：始终优先为0型从节点，因此不能成为主节点，对客户端应用程序不可见，但可以投票  
#延迟型(Delayed)节点：一定是优先级为0的从节点，也是隐藏型从节点。不能成主节点，也不能给客户端查询，用于数据集的“滚动备份”或运行“历史”快照，因此它们可以帮  
助您从各种人为错误中恢复  
#投票型节点和非投票型节点：复制集节点可以通过配置members[n].votes来决定该节点是否具有投票权利！members[n].votes值为1具有投票权利为投票型节点，为0则不  
可以投票即为不可投票节点。无表决权的节点必须优先级为0，也是优先级大于0的成员不能为0值。虽然无表决权的成员不在选举中投票，但这些成员持有副本集数据的副本，并且  
可以接受来自客户端应用程序的读取操作  
~~~

- Write concern：Write concern描述了在操作返回成功之前必须确认写操作的数据承载成员（即主节点成员和从节点成员，但不是仲裁者）的数量。成员只能在收到并成功应用写入后才能确认写入操作。对于副本集，默认的w：1的Write concern 要求在返回Write concern确认之前，只有Primary主节点确认写入。您可以指定一个大于1的整数值，以要求来自主节点的确认以及满足指定值所需的多个从节点，最多为副本集中数据承载成员的总数

- Read Preference：Read Preference是mongodb如何将读操作分配到节点中，默认情况下，应用程序将其读取操作定向到副本集中的主要成员（即读取首选项模式“primary”）。 但是，客户端可以指定读取首选项以将读取操作发送到辅助节点

--2.4 易扩展

- 分片(sharding)将数据分布在多个数据中心,MongoDB支持基于分片键创建数据区域

- 分片sharding是将数据水平切分到不同的物理节点。当应用数据越来越大的时候，数据量也会越来越大。当数据量增长 时，单台机器有可能无法存储数据或可接受的读取写入吞吐量。利用分片技术可以添加更多的机器来应对数据量增加 以及读写操作的要求

- 每一个分片(shard)是一个分区数据的逻辑集合。分片可能由单一服务器或者集群组成

- MongoDB 分片是基于区域(range)的。所以一个集合(collection)中的所有的对象都被存放到一个块(chunk)中,默认块的大小是 64Mb。当数据容量超过64 Mb，才有可能实施一个迁移，只有当存在不止一个块的时候，才会有多个分片获取数据的选项

- 块移动操作(moveChunk)失败了，不需要手动清除部分转移的文档吗，移动操作是一致(consistent)并且是确定性的

- MongoDB 分片是基于区域(range)的。所以一个集合(collection)中的所有的对象都被存放到一个块(chunk)中,默认块的大小是 64Mb。当数据容量超过64 Mb，才有可能实施一个迁移，只有当存在不止一个块的时候，才会有多个分片获取数据的选项

- 更新一个正在被迁移的块（Chunk）上的文档时，更新操作会立即发生在旧的块（Chunk）上，然后更改才会在所有权转移前复制到新的分片上

--2.5 MongoDB对事务ACID的支持

- 该部分主要参考[MongoDB是如何实现事务的ACID？](https://blog.csdn.net/popvip44/article/details/71487425)

- 原子性：单行/文档级的原子性，多行多文档级的原子性解决(通过大表和小表可以把相关的数据放到同一个文档中去。然后通过一条语句来执行操作)

- 一致性：支持多节点多分布式环境下的强一致性或最终一致性（弱一致性），MongoDB的数据一致性也叫可调一致性

- 隔离性：支持读提交

- 持久性：MongoDB同样是使用数据进来先写日志（日志刷盘的速度是非常快）然后在写入到数据库中，传统数据库这种方式叫做“WAL” Write-Ahead Logging（预写日志系统），而MongoDB叫做“journal”

--2.6 MongoDB的索引，该部分主要参考[MongoDB系列--轻松应对面试中遇到的MongonDB索引(index)问题](https://juejin.im/post/5d41924f5188255d5102e1fd#heading-15)

- 如果没有索引，MongoDB必须执行全集合collections扫描，即扫描集合中的每个文档，索引是B-Tree结构

- 支持单字段索引

~~~
#MongoDB可以在任何一个字段中创建索引，默认情况下，所有的集合(collections)会在_id字段中创建索引。_id索引是为防止客户端插入具有相同value的_id字段  
的文档Document，而且不能删除_id字段索引  
#在分片群集中使用_id索引，如果不使用_id字段作为分片键，则应用程序必须确保_id字段中值的唯一性以防止出错，解决方法为使用标准的自动生成的ObjectId来完成  
#一般单字段索引的value中，“1”指定按升序对项目进行排序的索引，“-1”指定按降序对项目进行排序的索引  


{
  "_id": ObjectId("570c04a4ad233577f97dc459"),
  "score": 1034,
  "location": { state: "NY", city: "New York" }
}
//创建单字段索引
 db.records.createIndex( { score: 1 } )
 //支持的查询  
db.records.find( { score: 2 } )
db.records.find( { score: { $gt: 10 } } )
~~~

- 支持复合索引

~~~
#复合索引指的是将多个key组合到一起创建索引，这样可以加速匹配多个键的查询  
#MongoDB对任何复合索引都限制了32个字段  
#复合索引创建字段索引的顺序是很重要，复合索引还可以支持与索引字段的前缀匹配的查询  


{
 "_id": ObjectId(...),
 "item": "Banana",
 "category": ["food", "produce", "grocery"],
 "location": "4th Street Store",
 "stock": 4,
 "type": "cases"
}
//创建复合索引
db.products.createIndex( { "item": 1, "stock": 1 } )
//支持的查询
db.products.find( { item: "Banana" } )
db.products.find( { item: "Banana", stock: { $gt: 5 } } )
//创建复合索引
db.products.createIndex({ "item": 1, "location": 1, "stock": 1 })
//前缀为：{ item: 1 }与{ item: 1, location: 1 }
//支持前缀查询为   
 db.products.find( { item: "Banana" } )
 db.products.find( { item: "Banana", location: “beijing”} )
//不支持前缀查询，不会提高查询效率
//不包含前缀字段
 db.products.find( { location: “beijing”} )
 db.products.find( { stock: { $gt: 5 } )
~~~

- 支持全文索引

~~~
#MongoDB提供了一种全文索引类型，支持在Collection中搜索字符串内容，对字符串与字符串数组创建全文可搜索的索引  
#一个collection最多只有一个全文索引  
#MongoDB提供权重以及通配符的创建方式  

{
  _id: 1,
  content: "This morning I had a cup of coffee.",
  about: "beverage",
  keywords: [ "coffee" ]
}
{
  _id: 2,
  content: "Who doesn't like cake?",
  about: "food",
  keywords: [ "cake", "food", "dessert" ]
}

//通过db.blog.createIndex来指定weight权重
db.blog.createIndex(
   {
     content: "text",
     keywords: "text",
     about: "text"
   },
   {
     weights: {
       content: 10,
       keywords: 5
     },
     name: "TextIndex"
   }
 )

//通配符索引
db.collection.createIndex( { "$**": "text" } )

~~~

- 支持hash索引

~~~
#散列索引使用散列函数来计算索引字段值的散列值。 散列函数会折叠嵌入的文档并计算整个值的散列值  
#散列索引支持使用散列分片键进行分片。 基于散列的分片使用字段的散列索引作为分片键来分割整个分片群集中的数据  

db.collection.createIndex( { _id: "hashed" } )

~~~

**参考**

- [spring定时任务详解（@Scheduled注解）](https://blog.csdn.net/qq_39101581/article/details/79308851)
- [Java操作MongoDB实现CRUD](https://my.oschina.net/lihaoshan/blog/1821360)
- [MongoDB 组合多个条件查询（𝑎𝑛𝑑、in、𝑔𝑡𝑒、lte）](https://www.cnblogs.com/hapjin/p/7450309.html)
- [快2020年了，赶紧收藏起MongoDB面试题轻松面对BAT灵魂式的拷问](https://juejin.im/post/5d9ee1ce5188255820783df3#heading-0)
- [BSON的介绍及BSON与JSON的区别](https://blog.csdn.net/m0_38110132/article/details/77716792?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-1&depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-1)